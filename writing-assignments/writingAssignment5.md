Listening to this podcast really made me think back on the topic of morality and ethics in code I brought up in one of my previous writing assignments. A la Jurassic Park, Clearview’s founder Hoan Thoan That is so focused on the engineering and building that he failed to consider the potential repercussions of his technology. Richard S. gave him a problem, and like any good engineer, he built a solution, not realizing that this whole time he was building a weapon. Going through a computer science curriculum myself, I completely relate that situation. After having spent all this time learning about how computers work and how we humans communicate, it’s not surprising that a little bit of their optimized, scientific thinking stays with us too. If you want a perfect example of this, let me list the three thoughts I had after reading about That’s algorithm:


“ How does it work? I could probably do that if I spent the time”,


“ This is definitely a Jurassic Park moment, I should reference it in my response ”,


“Can I create an Anti-Clearview (Cecity???) rendering Hoan’s algorithm useless on a given person?”

Much like Hoan, the consequences of building such a software did not come until I had thought of an approach. I did not think that much like Clearview can be used to over police and impose harsh rule of law, an anti-Clearview could be used by ill intentioned people to escape detection. Sadly some experts such as NYU professor Clay Shirky think that we cannot enjoy the benefits of data collection systems without exposing ourselves to their misuse. They go even further by proposing that the tool in itself is not dangerous, but rather the wielder. In light of this, I think strict monitoring of not only who gets to access, but also who gets to build these tools should be better regulated. I genuinely fail to see why one singular coder should be able to find any and all online people with a simple picture.
